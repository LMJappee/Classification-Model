{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44a2c393",
   "metadata": {},
   "source": [
    "# A1: Classification Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b882dc2",
   "metadata": {},
   "source": [
    "Machine Learning - DAT-5303 - BMBAN2<br>\n",
    "Lars Marius Strømberg Jappée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dca55cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import plot_tree                   # tree plots\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "import gender_guesser.detector as gender # guess gender based on (given) name\n",
    "\n",
    "# specifying file\n",
    "file = \"./GOT_character_predictions.xlsx\"\n",
    "\n",
    "# import excel file\n",
    "got = pd.read_excel(io = file,\n",
    "                    header = 0,\n",
    "                    sheet_name = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11d6db",
   "metadata": {},
   "source": [
    "# User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "480d5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.10,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "x_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the x data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing x_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed,\n",
    "                                                        stratify     = y_data)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')\n",
    "\n",
    "\n",
    "#########################\n",
    "# mv_flagger\n",
    "#########################\n",
    "def mv_flagger(df):\n",
    "    \"\"\"\n",
    "Flags all columns that have missing values with 'm-COLUMN_NAME'.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "df : DataFrame to flag missing values\n",
    "\n",
    "\n",
    "RETURNS\n",
    "-------\n",
    "DataFrame with missing value flags.\"\"\"\n",
    "\n",
    "\n",
    "    for col in df:\n",
    "\n",
    "        if df[col].isnull().astype(int).sum() > 0:\n",
    "            df['m_'+col] = df[col].isnull().astype(int)\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "#########################\n",
    "# text_split_feature\n",
    "#########################\n",
    "def text_split_feature(col, df, sep=' ', new_col_name='number_of_names'):\n",
    "    \"\"\"\n",
    "Splits values in a string Series (as part of a DataFrame) and sums the number\n",
    "of resulting items. Automatically appends summed column to original DataFrame.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "col          : column to split\n",
    "df           : DataFrame where column is located\n",
    "sep          : string sequence to split by, default ' '\n",
    "new_col_name : name of new column after summing split, default\n",
    "               'number_of_names'\n",
    "\"\"\"\n",
    "    \n",
    "    df[new_col_name] = 0\n",
    "    \n",
    "    \n",
    "    for index, val in df.iterrows():\n",
    "        df.loc[index, new_col_name] = len(df.loc[index, col].split(sep = ' '))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70196d6",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95280271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the mv_flagger function to get missing values and potentially use them as a boolean\n",
    "got = mv_flagger(df = got)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d457a05e",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbecd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting popularity into three popular and unpopular, and neutral.\n",
    "\n",
    "# creating different popularity columns\n",
    "got['popular'] = 0\n",
    "got['unpopular'] = 0\n",
    "got['neutral'] = 0\n",
    "\n",
    "# replacing values based on condition\n",
    "for index, val in got.iterrows():\n",
    "\n",
    "    if got.loc[index, 'popularity'] > 0.5:\n",
    "        got.loc[index, 'popular'] = 1\n",
    "        \n",
    "    elif got.loc[index, 'popularity'] > 0:\n",
    "        got.loc[index, 'neutral'] = 1\n",
    "       \n",
    "    elif got.loc[index, 'popularity'] == 0:\n",
    "        got.loc[index, 'unpopular'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b5b64",
   "metadata": {},
   "source": [
    "### Year Calculation and New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ce8c7",
   "metadata": {},
   "source": [
    "No known Character has lived beyond 100 years. Setting anyone born more than 100 years ago in a separate columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707c4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating year and oldest recorded person\n",
    "# std to remove any outliers in both directions, given a story will most\n",
    "# likely have people living \"now\" in their timeline using mode to set year\n",
    "yearstd = got.loc[ : , 'dateOfBirth'].std()\n",
    "yearstd = got.loc[ : , 'dateOfBirth'] < yearstd\n",
    "year = got[yearstd].loc[ : , 'dateOfBirth'] + got[yearstd].loc[ : , 'age']\n",
    "year = year.mode()[0]\n",
    "\n",
    "yearbefore = year - got['age'].max()\n",
    "yearbefore = int(yearbefore)\n",
    "\n",
    "# creating a born in a different era column based on birth year\n",
    "got[f'birth_before_{yearbefore}'] = 0\n",
    "\n",
    "# replacing values based on condition\n",
    "for index, val in got.iterrows():\n",
    "    if got.loc[index, 'dateOfBirth'] < yearbefore:\n",
    "        got.loc[index, f'birth_before_{yearbefore}'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15cb3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating different column based on if age + year of birth is lower than current year\n",
    "got['age_birth_year'] = 0\n",
    "\n",
    "# replacing values based on condition\n",
    "for index, val in got.iterrows():\n",
    "    if got.loc[index, 'dateOfBirth'] + got.loc[index, 'age'] < year:\n",
    "        got.loc[index, 'age_birth_year'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b770f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating different column based on birth year is equal or greater than current\n",
    "# to see if still alive based on age\n",
    "got['age_equal_year'] = 0\n",
    "\n",
    "# replacing values based on condition\n",
    "for index, val in got.iterrows():\n",
    "    if got.loc[index, 'dateOfBirth'] + got.loc[index, 'age'] >= year:\n",
    "        got.loc[index, 'age_equal_year'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d572d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting name and creating count of nr of names using user defined function\n",
    "text_split_feature('name', got, sep=' ', new_col_name='nr_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be3753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating count of how many times in book\n",
    "got['nr_books'] = got['book1_A_Game_Of_Thrones'] +\\\n",
    "got['book2_A_Clash_Of_Kings'] +\\\n",
    "got['book3_A_Storm_Of_Swords'] +\\\n",
    "got['book4_A_Feast_For_Crows'] +\\\n",
    "got['book5_A_Dance_with_Dragons']\n",
    "\n",
    "got['referenced'] = 0\n",
    "\n",
    "# looping to to create boolean of if the person is in book or referenced\n",
    "for index, val in got.iterrows():\n",
    "     \n",
    "    if got.loc[ index , 'nr_books'] == 0:\n",
    "        got.loc[index, 'referenced'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b0c92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two in a row then not in book\n",
    "got['two_then_not'] = 0\n",
    "\n",
    "for index, val in got.iterrows():\n",
    "    \n",
    "    # setting two then not in next book\n",
    "    if got.loc[ index , 'book1_A_Game_Of_Thrones'] == 1\\\n",
    "    and got.loc[ index , 'book2_A_Clash_Of_Kings'] == 1\\\n",
    "    and got.loc[ index , 'book3_A_Storm_Of_Swords'] == 0:\n",
    "        got.loc[index, 'two_then_not'] = 1\n",
    "        \n",
    "    if got.loc[ index , 'book2_A_Clash_Of_Kings'] == 1\\\n",
    "    and got.loc[ index , 'book3_A_Storm_Of_Swords'] == 1\\\n",
    "    and got.loc[ index , 'book4_A_Feast_For_Crows'] == 0:\n",
    "        got.loc[index, 'two_then_not'] = 1\n",
    "        \n",
    "    if got.loc[ index , 'book3_A_Storm_Of_Swords'] == 1\\\n",
    "    and got.loc[ index , 'book4_A_Feast_For_Crows'] == 1\\\n",
    "    and got.loc[ index , 'book5_A_Dance_with_Dragons'] == 0:\n",
    "        got.loc[index, 'two_then_not'] = 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "732045bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a boolean of only in book five\n",
    "got['only_book5'] = 0\n",
    "\n",
    "for index, val in got.iterrows():\n",
    "    \n",
    "    # checking for Miss.\n",
    "    if got.loc[ index , 'book5_A_Dance_with_Dragons'] == 1\\\n",
    "    and got.loc[ index , 'nr_books'] == 1:\n",
    "        got.loc[index, 'only_book5'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e986db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating boolean for people only in last book\n",
    "got['not_in_last'] = 0\n",
    "\n",
    "for index, val in got.iterrows():\n",
    "    \n",
    "    # checking for Miss.\n",
    "    if got.loc[ index , 'nr_books'] >= 3\\\n",
    "    and got.loc[ index , 'book5_A_Dance_with_Dragons'] == 0:\n",
    "        got.loc[index, 'not_in_last'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e995e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f729154",
   "metadata": {},
   "source": [
    "## Gender Guesser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c0f28",
   "metadata": {},
   "source": [
    "Gender guesser could not be used within time limit, an option would have been <br>\n",
    "to only use it on a few given an if statement. Or to export to excel and include <br>\n",
    "with submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a4515ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # placeholder list\n",
    "# placeholder_lst = []\n",
    "\n",
    "# # looping over each name\n",
    "# for index, col in got.iterrows():\n",
    "    \n",
    "#     # splitting each name\n",
    "#     name_split = got.loc[index, 'name'].split()\n",
    "    \n",
    "#     # appending placeholder_lst with the results\n",
    "#     placeholder_lst.append(name_split)\n",
    "    \n",
    "\n",
    "# # converting placeholder_lst into a DataFrame \n",
    "# name_split = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "# # renaming column to concatenate\n",
    "# name_split.columns = ['first_name', 'name2', 'name3', 'name4', 'name5', 'name6']\n",
    "\n",
    "# # concatenating first name with got\n",
    "# got = pd.concat([got, name_split['first_name']],\n",
    "#                    axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc4d46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # guessing gender based on (given) name\n",
    "\n",
    "# # placeholder list\n",
    "# placeholder_lst = []\n",
    "\n",
    "# # looping to guess gender\n",
    "# for name in got['first_name']:\n",
    "#     guess = gender.Detector().get_gender(name)\n",
    "#     print(guess)\n",
    "#     placeholder_lst.append(guess)\n",
    "\n",
    "# # converting list into a series\n",
    "# got['gender_guess'] = pd.Series(placeholder_lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1702c44",
   "metadata": {},
   "source": [
    "### Dummies one hot adding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b970868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # one hot encoding variables\n",
    "# one_hot_gender_guess       = pd.get_dummies(got['gender_guess'])\n",
    "\n",
    "# # joining codings together\n",
    "# got = got.join(other = [one_hot_gender_guess])\n",
    "\n",
    "# # dropping categorical variables after they've been encoded\n",
    "# got = got.drop(['female', 'male', 'mostly_female', 'mostly_male', 'andy',\n",
    "#                 'gender_guess', 'first_name'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f30d8",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5523bd",
   "metadata": {},
   "source": [
    "Testing area for features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "740c3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring explanatory variables\n",
    "# got_data = got.drop(['isAlive'],\n",
    "#                              axis = 1)\n",
    "\n",
    "# # declaring response variable\n",
    "# got_target = got.loc[ : ,'isAlive']\n",
    "\n",
    "# # train-test split with stratification\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#             got_data,\n",
    "#             got_target,\n",
    "#             test_size    = 0.10,\n",
    "#             random_state = 219,\n",
    "#             stratify     = got_target) # preserving balance\n",
    "\n",
    "# # merging training data for statsmodels\n",
    "# got_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77858ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating a (Pearson) correlation matrix\n",
    "# df_corr = got.corr().round(2)\n",
    "\n",
    "# # printing (Pearson) correlations with isAlive\n",
    "# print(df_corr.loc['isAlive'].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad72a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val in got:\n",
    "#     print(f\"{val} + \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40855755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # instantiating a logistic regression model object\n",
    "# logistic_full = smf.logit(formula = \"\"\" isAlive ~ \n",
    "# nr_books + \n",
    "# popularity + \n",
    "# age_birth_year\n",
    "# \"\"\",\n",
    "# data    = got)\n",
    "\n",
    "\n",
    "# # fitting the model object\n",
    "# results_full = logistic_full.fit(maxiter = 1000)\n",
    "\n",
    "\n",
    "# # checking the results SUMMARY\n",
    "# results_full.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9bc121",
   "metadata": {},
   "source": [
    "# Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0565f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "'not_in_last',\n",
    "'book1_A_Game_Of_Thrones',\n",
    "'book2_A_Clash_Of_Kings',\n",
    "'book4_A_Feast_For_Crows',\n",
    "'age_birth_year',\n",
    "'age_equal_year',\n",
    "'popularity',\n",
    "'only_book5',\n",
    "'two_then_not'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "705c4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split with the full model\n",
    "got_data   =  got.loc[: , variables]\n",
    "got_target =  got.loc[ : , 'isAlive']\n",
    "\n",
    "# This is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = got_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81739dcf",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dacc5e",
   "metadata": {},
   "source": [
    "The tuning array were chosen based on the largest impact i could see with the <br>\n",
    "least fine tuning. Mostly using the different named options, with some <br>\n",
    "exceptions. The required criterion was included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f08180",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b0d25b",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d76c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# class_weight = ['balanced', 'dict', 'None'] # Keeping to the simplest fewest variables to effectivize.\n",
    "# solver_range = ['newton-cg', 'sag', 'lbfgs', 'saga'] # Keeping to the simplest fewest variables to effectivize.\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'class_weight' : class_weight,\n",
    "#               'solver'     : solver_range}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# lr_tuned = LogisticRegression(random_state = 219,\n",
    "#                               max_iter     = 100) # increased for convergence\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "#                                  param_distributions = param_grid, # parameters to tune\n",
    "#                                  cv                  = 3,          # how many folds in cross-validation\n",
    "#                                  n_iter              = 12,        # number of combinations of hyperparameters to try\n",
    "#                                  random_state        = 219,        # starting point for random sequence\n",
    "#                                  scoring = make_scorer(\n",
    "#                                            roc_auc_score,\n",
    "#                                            needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# lr_tuned_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "# print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7482b89f",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79ee4671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7236\n",
      "Testing  ACCURACY: 0.7846\n",
      "AUC Score        : 0.8159\n",
      "\n",
      "True Negatives : 44\n",
      "False Positives: 6\n",
      "False Negatives: 36\n",
      "True Positives : 109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'newton-cg',\n",
    "                            class_weight = 'balanced',\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING to the train dataset(could use full, due to tuning)\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51607618",
   "metadata": {},
   "source": [
    "## Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2ec939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', -0.0)\n",
      "('not_in_last', -0.46)\n",
      "('book1_A_Game_Of_Thrones', -0.48)\n",
      "('book2_A_Clash_Of_Kings', -0.4)\n",
      "('book4_A_Feast_For_Crows', 1.34)\n",
      "('age_birth_year', -4.15)\n",
      "('age_equal_year', 3.94)\n",
      "('popularity', -2.62)\n",
      "('only_book5', 0.65)\n",
      "('two_then_not', -0.22)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "logreg_model_values = zip(got_data.columns,\n",
    "                          logreg_fit.coef_.ravel().round(decimals = 2))\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "logreg_model_lst = [('intercept', logreg_fit.intercept_[0].round(decimals = 2))]\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in logreg_model_values:\n",
    "    logreg_model_lst.append(val)\n",
    "    \n",
    "# checking the results\n",
    "for pair in logreg_model_lst:\n",
    "    print(pair)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01b181",
   "metadata": {},
   "source": [
    "# Classification Trees (CART Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc411cb6",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f2406b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# criterion = ['gini', 'entropy']\n",
    "# splitter  = ['best', 'random']\n",
    "# max_depth = np.arange(2, 8)\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'criterion' : criterion,\n",
    "#               'splitter'  : splitter,\n",
    "#               'max_depth' : max_depth,}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # RandomizedSearchCV object\n",
    "# tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "#                                    param_distributions   = param_grid,\n",
    "#                                    cv                    = 3,\n",
    "#                                    n_iter                = 24,\n",
    "#                                    random_state          = 219,\n",
    "#                                    scoring = make_scorer(roc_auc_score,\n",
    "#                                              needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# tuned_tree_cv.fit(got_data, got_target)\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e782e588",
   "metadata": {},
   "source": [
    "## Classification Trees (CART Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a953a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8521\n",
      "Testing  ACCURACY: 0.9128\n",
      "AUC Score        : 0.8366\n",
      "\n",
      "True Negatives : 34\n",
      "False Positives: 16\n",
      "False Negatives: 1\n",
      "True Positives : 144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "tree_pruned = DecisionTreeClassifier(max_depth = 7,\n",
    "                                     min_samples_leaf = 30, # to keep enough samples in each\n",
    "                                     random_state = 219,\n",
    "                                     splitter = 'best',\n",
    "                                     criterion = 'entropy')\n",
    "\n",
    "\n",
    "# FITTING to the train dataset(could use full, due to tuning)\n",
    "tree_pruned_fit = tree_pruned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "tree_pruned_pred = tree_pruned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_pruned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = tree_pruned_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = tree_pruned_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = tree_pruned_pred).round(4)\n",
    "\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_pruned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5377a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting feature importance\n",
    "plot_feature_importances(tree_pruned_fit,\n",
    "                         train = x_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5d8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "067c78c1",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48278b8c",
   "metadata": {},
   "source": [
    "## Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5bc2748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(got_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "x_scaled     = scaler.transform(got_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            x_scaled_df,\n",
    "            got_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = got_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aca22d",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4992f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # determining the optimal number of neighbors\n",
    "# opt_neighbors = optimal_neighbors(x_data        = x_scaled_df,\n",
    "#                                   y_data        = got_target,\n",
    "#                                   response_type = 'class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d18a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# n_neighbors = [opt_neighbors]\n",
    "# weights  = ['uniform', 'distance']\n",
    "# algorithm      = ['auto', 'ball_tree', 'ball_tree', 'kd_tree', 'brute']\n",
    "# leaf_size       = np.arange(10, 100)\n",
    "# metric    = ['minkowski', 'euclidean', 'manhattan']\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'n_neighbors' : n_neighbors,\n",
    "#               'weights'         : weights,\n",
    "#               'algorithm'        : algorithm,\n",
    "#               'leaf_size' : leaf_size,\n",
    "#               'metric'     : metric}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# tuned_knn = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "# # RandomizedSearchCV object\n",
    "# tuned_knn_cv = RandomizedSearchCV(estimator             = tuned_knn,\n",
    "#                                    param_distributions   = param_grid,\n",
    "#                                    cv                    = 3,\n",
    "#                                    n_iter                = 1000,\n",
    "#                                    random_state          = 219,\n",
    "#                                    scoring = make_scorer(roc_auc_score,\n",
    "#                                              needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# tuned_knn_cv.fit(got_data, got_target)\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", tuned_knn_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", tuned_knn_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d3a569",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6433201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8995\n",
      "Testing  ACCURACY: 0.8615\n",
      "AUC Score        : 0.8414\n",
      "\n",
      "True Negatives : 40\n",
      "False Positives: 10\n",
      "False Negatives: 17\n",
      "True Positives : 128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = 14,\n",
    "                               weights = 'distance',\n",
    "                               metric = 'euclidean',\n",
    "                               leaf_size = 76,\n",
    "                               algorithm = 'brute')\n",
    "\n",
    "# FITTING to the train dataset(could use full, due to tuning)\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = knn_pred).round(4)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "knn_tn, \\\n",
    "knn_fp, \\\n",
    "knn_fn, \\\n",
    "knn_tp = confusion_matrix(y_true = y_test_scaled, y_pred = knn_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {knn_tn}\n",
    "False Positives: {knn_fp}\n",
    "False Negatives: {knn_fn}\n",
    "True Positives : {knn_tp}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f779826e",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145870ae",
   "metadata": {},
   "source": [
    "## Hyper Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d66c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # INSTANTIATING a random forest model with default values\n",
    "# rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "#                                     criterion        = 'gini',\n",
    "#                                     max_depth        = 4,\n",
    "#                                     min_samples_leaf = 1,\n",
    "#                                     bootstrap        = True,\n",
    "#                                     warm_start       = False,\n",
    "#                                     random_state     = 219)\n",
    "\n",
    "# # FITTING the training data\n",
    "# rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# # PREDICTING based on the testing set\n",
    "# rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# # declaring a hyperparameter space\n",
    "# criterion = ['gini', 'entropy']\n",
    "# max_depth = np.arange(2, 8)\n",
    "# n_estimators = np.arange(10, 500, 10)\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'criterion'     : criterion,\n",
    "#               'max_depth'        : max_depth,\n",
    "#               'n_estimators' : n_estimators}\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "# # GridSearchCV object\n",
    "# forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "#                                param_distributions = param_grid,\n",
    "#                                cv         = 3,\n",
    "#                                n_iter     = 558,\n",
    "#                                scoring    = make_scorer(roc_auc_score,\n",
    "#                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# forest_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c6f05",
   "metadata": {},
   "source": [
    "## Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe57ab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.8652\n",
      "Forest Tuned Testing  ACCURACY: 0.9026\n",
      "Forest Tuned AUC Score        : 0.8362\n",
      "\n",
      "True Negatives : 35\n",
      "False Positives: 15\n",
      "False Negatives: 4\n",
      "True Positives : 141\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING with best_estimator\n",
    "forest_tuned = RandomForestClassifier(criterion='gini', \n",
    "                                      n_estimators=70, \n",
    "                                      random_state=219, \n",
    "                                      max_depth = 7)\n",
    "\n",
    "\n",
    "# FITTING to the train dataset(could use full, due to tuning)\n",
    "forest_tuned_fit = forest_tuned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                       y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc\n",
    "\n",
    "# plotting feature importances\n",
    "plot_feature_importances(forest_tuned_fit,\n",
    "                         train = x_train,\n",
    "                         export = False)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec4669",
   "metadata": {},
   "source": [
    "# Gradient Boosted Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab52151f",
   "metadata": {},
   "source": [
    "## Hyper Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1abb8ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# learning_rate        = np.arange(0.1, 2.2, 0.5)\n",
    "# n_estimators    = np.arange(1, 200, 25)\n",
    "# max_depth        = np.arange(2, 8, 1)\n",
    "# min_samples_leaf   = np.arange(30, 51, 5)\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'learning_rate' : learning_rate,\n",
    "#               'n_estimators'     : n_estimators,\n",
    "#               'max_depth'  : max_depth,\n",
    "#               'min_samples_leaf'    : min_samples_leaf}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    "#                            param_distributions = param_grid,\n",
    "#                            cv                  = 3,\n",
    "#                            n_iter              = 500,\n",
    "#                            random_state        = 219,\n",
    "#                            scoring             = make_scorer(roc_auc_score,\n",
    "#                                                  needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# full_gbm_cv.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4da25e",
   "metadata": {},
   "source": [
    "## Gradient Boosted Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fa87ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8212\n",
      "Testing  ACCURACY: 0.8923\n",
      "AUC Score        : 0.8686\n",
      "\n",
      "True Negatives : 41\n",
      "False Positives: 9\n",
      "False Negatives: 12\n",
      "True Positives : 133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING with best_estimator\n",
    "gbm_tuned = GradientBoostingClassifier(n_estimators = 1,\n",
    "                                       min_samples_leaf     = 30,\n",
    "                                       max_depth  = 5,\n",
    "                                       learning_rate  = 1.1)\n",
    "\n",
    "\n",
    "# FITTING to the train dataset(could use full, due to tuning)\n",
    "gbm_tuned_fit = gbm_tuned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")\n",
    "\n",
    "# declaring model performance objects\n",
    "gbm_train_acc = gbm_tuned_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967740bc",
   "metadata": {},
   "source": [
    "# Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0366cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model         AUC Score      Training Accuracy      Testing Accuracy    TN, FP, FN, TP\n",
      "-----         ---------      -----------------      ----------------    --------------\n",
      "Logistic      0.8159         0.7236                 0.7846              (44, 6, 36, 109)\n",
      "Tree          0.8366         0.8521                 0.9128              (34, 16, 1, 144)\n",
      "KNN           0.8414         0.8995                 0.8615              (40, 10, 17, 128)\n",
      "Random Forest 0.8362         0.8652                 0.9026              (35, 15, 4, 141)\n",
      "*GBM          0.8686         0.8212                 0.8923              (41, 9, 12, 133)\n",
      "\n",
      "*Final Model\n"
     ]
    }
   ],
   "source": [
    "# comparing results and choosing final, based on high AUC and all scores lower \n",
    "# than 0.9\n",
    "print(f\"\"\"\n",
    "Model         AUC Score      Training Accuracy      Testing Accuracy\\\n",
    "    TN, FP, FN, TP\n",
    "-----         ---------      -----------------      ----------------\\\n",
    "    --------------\n",
    "Logistic      {logreg_auc_score}         {logreg_train_score}\\\n",
    "                 {logreg_test_score}\\\n",
    "              {logreg_tn, logreg_fp, logreg_fn, logreg_tp}\n",
    "Tree          {pruned_tree_auc_score}         {pruned_tree_train_score}\\\n",
    "                 {pruned_tree_test_score}\\\n",
    "              {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "KNN           {knn_auc_score}         {knn_train_score}\\\n",
    "                 {knn_test_score}\\\n",
    "              {knn_tn, knn_fp, knn_fn, knn_tp}\n",
    "Random Forest {forest_tuned_auc}         {forest_tuned_train_score}\\\n",
    "                 {forest_tuned_test_score}\\\n",
    "              {tuned_rf_tn, tuned_rf_fp, tuned_rf_fn, tuned_rf_tp}\n",
    "*GBM          {gbm_auc}         {gbm_train_acc}\\\n",
    "                 {gbm_test_acc}\\\n",
    "              {gbm_tuned_tn, gbm_tuned_fp, gbm_tuned_fn, gbm_tuned_tp}\n",
    "\n",
    "*Final Model\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d4455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274.901px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
